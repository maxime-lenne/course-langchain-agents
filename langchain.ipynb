{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f4459b",
   "metadata": {},
   "source": [
    "![LangChain](img/langchain.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511a0f0",
   "metadata": {},
   "source": [
    "Les **Agents** dans LangChain ouvrent la voie √† des syst√®mes plus dynamiques, capables de **raisonner √©tape par √©tape** et d‚Äô**interagir avec des outils** pour accomplir des t√¢ches complexes.\n",
    "\n",
    "Contrairement aux cha√Ænes statiques (chains), **‚ö†Ô∏è un agent ne suit pas un chemin pr√©d√©fini**. **Il s‚Äôappuie sur un LLM** qui d√©cide dynamiquement, √† chaque √©tape, quelle action entreprendre : quel outil utiliser, quelles informations rechercher ou comment poursuivre, en fonction du contexte.\n",
    "\n",
    "Les outils, ou **tools**, sont des fonctions encapsul√©es que l‚Äôagent peut appeler, il peut s'agir de fonctions pour interroger une base de donn√©es, de consulter une API, ou d‚Äôex√©cuter un calcul.\n",
    "\n",
    "**Gr√¢ce √† cette combinaison :**\n",
    "\n",
    "> raisonnement du LLM ‚Üí proposition d‚Äôaction ‚Üí ex√©cution par l‚Äôagent ‚Üí observation ‚Üí nouveau raisonnement ‚Üí et ainsi de suite...\n",
    "\n",
    "... un agent LangChain devient un orchestrateur intelligent, capable de r√©soudre des probl√®mes ouverts ou de r√©pondre √† des requ√™tes complexes, sans suivre un script rigide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb160db",
   "metadata": {},
   "source": [
    "![Agent](img/agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3075ae",
   "metadata": {},
   "source": [
    "L‚Äôagent suit un **sch√©ma it√©ratif** bas√© sur le pattern **ReAct (Reasoning + Acting)**.\n",
    "√Ä partir d‚Äôune requ√™te, l'agent interagit avec un mod√®le de langage (LLM) qui raisonne √©tape par √©tape (**Thought**) et propose des actions (**Action**) √† effectuer √† l‚Äôaide d‚Äôoutils disponibles.\n",
    "L‚Äôagent ex√©cute ces actions, collecte les r√©sultats (**Observation**), et les renvoie au LLM pour affiner son raisonnement.\n",
    "Ce cycle **ReAct** se r√©p√®te jusqu‚Äô√† ce que le LLM formule une r√©ponse finale (**Final Answer**), que l‚Äôagent retourne √† l‚Äôutilisateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a13fb",
   "metadata": {},
   "source": [
    "![Hugging Face](img/hugging_face.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cafb689",
   "metadata": {},
   "source": [
    "# 1. Chargement du mod√®le\n",
    "___\n",
    "\n",
    "## LLM local :\n",
    "\n",
    "Dans cette section, nous chargeons un mod√®le de langage local gr√¢ce √† **Ollama**. Cela permet de travailler avec un **LLM directement sur notre machine**, sans connexion √† une API externe.\n",
    "\n",
    "Nous utilisons ici la classe `ChatOllama` de **LangChain**, qui nous permet d‚Äôinteragir facilement avec un mod√®le comme llama3 d√©j√† t√©l√©charg√© via Ollama.\n",
    "\n",
    "GTP-OSS:20b, Mistral-Small3.2 24B GLM 4.7 Flash\n",
    "\n",
    "## LLM Cloud :\n",
    "Mistral"
   ]
  },
  {
   "cell_type": "code",
   "id": "7301c899",
   "metadata": {},
   "source": [
    "\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Chargement des cl√©s d'API se trouvant dans le fichier .env.\n",
    "# Ceci permet d'utiliser des mod√®les en ligne comme gpt-x, deepseek-x, etc...\n",
    "load_dotenv(override=True)\n",
    "\n",
    "model = ChatOllama(model=\"glm-4.7-flash\")\n",
    "\n",
    "#model = ChatMistralAI(model=\"mistral-large-latest\", api_key=os.getenv(\"MISTRAL_API_KEY\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a48a0cd4",
   "metadata": {},
   "source": [
    "# 2. Agent standard\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce1aa8",
   "metadata": {},
   "source": [
    "Un agent standard permet d‚Äôutiliser un mod√®le de langage avec un ou plusieurs **outils externes**, comme des fonctions Python, pour r√©pondre √† une t√¢che sp√©cifique.\n",
    "Cet agent **fonctionne sans m√©moire** : il ne conserve **aucun historique des interactions pr√©c√©dentes**. Chaque question est trait√©e de mani√®re ind√©pendante, comme une **requ√™te isol√©e**.\n",
    "\n",
    "Dans cet exemple, l‚Äôagent utilise un outil simple pour r√©pondre √† la question ¬´ Quelle heure est-il ? ¬ª, en appelant une fonction qui retourne l‚Äôheure actuelle.\n",
    "Son comportement est guid√© par un prompt ReAct standard charg√© depuis LangChain Hub, qui lui permet de raisonner et de d√©cider quand utiliser un outil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f33b1",
   "metadata": {},
   "source": [
    "### 2.1 Pr√©paration des outils"
   ]
  },
  {
   "cell_type": "code",
   "id": "50c53956",
   "metadata": {},
   "source": "# D√©finition de l'outil avec le d√©corateur @tool (API moderne LangChain v1).\n# Le docstring sert de description : le LLM l'utilise pour d√©cider quand appeler l'outil.\n# Les type hints sont obligatoires : ils d√©finissent automatiquement le sch√©ma d'entr√©e/sortie.\n@tool\ndef get_current_time() -> str:\n    \"\"\"Use this tool to get the current time.\"\"\"\n    return datetime.now().strftime(\"%H:%M\")\n\n# Liste des outils disponibles pour l'agent.\ntools = [get_current_time]",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "09e15c58",
   "metadata": {},
   "source": [
    "### 2.2 Pr√©paration et usage de l'agent"
   ]
  },
  {
   "cell_type": "code",
   "id": "e5c311b6",
   "metadata": {},
   "source": "# Cr√©ation de l'agent avec l'API moderne create_agent (LangChain v1).\n# Plus besoin de prompt Hub, d'AgentExecutor ni de create_react_agent.\nagent = create_agent(\n    model,\n    tools=tools\n)\n\n# Invocation de l'agent : le format d'entr√©e est d√©sormais bas√© sur les messages.\nresponse = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Quelle heure est-il ?\"}]})\n\ndisplay(Markdown(response[\"messages\"][-1].content))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9bbeab8",
   "metadata": {},
   "source": [
    "### üß© Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909bdabb",
   "metadata": {},
   "source": [
    "#### Exercice 1\n",
    "\n",
    "Cr√©ez un agent capable de faire des conversions de temp√©rature. Votre agent doit pouvoir r√©pondre √† des questions comme :\n",
    "- *‚ÄúQuelle est la temp√©rature en Celsius pour 100 Fahrenheit ?‚Äù*\n",
    "- *‚ÄúConvertis 37.5 degr√©s Celsius en Fahrenheit.‚Äù*\n",
    "\n",
    "üí° Utilisez 2 **tools** diff√©rents\n",
    "\n",
    "üí™üèª Bonus : Autoriser des entr√©es plus souples, comme ‚ÄúConvertis 100 F en C‚Äù ou ‚ÄúCelsius pour 212¬∞F‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "id": "7b977196",
   "metadata": {},
   "source": [
    "# Votre code ici"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f45e9a8",
   "metadata": {},
   "source": [
    "# 2. Agent conversationnel\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c71cf",
   "metadata": {},
   "source": "Un agent conversationnel est con√ßu pour g√©rer un **dialogue continu**, en conservant une **m√©moire des √©changes pr√©c√©dents**. Contrairement √† l'agent standard qui traite chaque requ√™te ind√©pendamment, un agent conversationnel **peut adapter ses r√©ponses en fonction du contexte accumul√© dans la conversation**.\n\nCe type d'agent est particuli√®rement utile pour construire des assistants interactifs, des conseillers ou des syst√®mes de FAQ qui doivent s'adapter aux intentions de l'utilisateur au fil du temps.\n\nAvec LangChain v1, la m√©moire est g√©r√©e par **LangGraph** via `MemorySaver`. Chaque conversation est identifi√©e par un `thread_id` dans la configuration, ce qui permet de maintenir des sessions ind√©pendantes et persistantes."
  },
  {
   "cell_type": "code",
   "id": "3a3486d3",
   "metadata": {},
   "source": "# Cr√©ation d'un agent conversationnel avec m√©moire persistante.\n# MemorySaver stocke l'historique des √©changes en m√©moire, associ√© √† un thread_id.\nconversational_agent = create_agent(\n    model,\n    tools=tools,\n    checkpointer=MemorySaver()\n)\n\n# Chaque thread_id identifie une session de conversation ind√©pendante.\nconfig = {\"configurable\": {\"thread_id\": \"session-1\"}}\n\n# Boucle interactive terminale\nwhile True:\n    user_input = input(\"Vous : \")\n    clear_output(wait=True)                         # Efface l'affichage pr√©c√©dent\n    display(Markdown(f\"**Vous :** {user_input}\"))   # Affiche la requ√™te de l'utilisateur\n\n    if user_input.lower() in [\"stop\", \"exit\", \"quit\"]:\n        print(\"Fin de la conversation.\")\n        break\n\n    response = conversational_agent.invoke(\n        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n        config\n    )\n    display(Markdown(response[\"messages\"][-1].content))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fad82676",
   "metadata": {},
   "source": [
    "### üß© Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abd6bb",
   "metadata": {},
   "source": [
    "#### Exercice 2\n",
    "\n",
    "Reprenez vos travaux sur l'exercice pr√©c√©dent pour y introduire un aspect conversationnel gr√¢ce √† une boucle de conversation et √† la gestion de la m√©moire via `MemorySaver` et `thread_id`."
   ]
  },
  {
   "cell_type": "code",
   "id": "f35cb257",
   "metadata": {},
   "source": [
    "# Votre code ici"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
